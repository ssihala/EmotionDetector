{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbb79b28-55e1-41bf-ba78-2e4c35855526",
   "metadata": {},
   "source": [
    "# CAI4104 Final Project: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ccbe021-95a9-42d3-a6b3-02f319055f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 15:12:33.359928: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "### Python version: 3.10.13 (main, Sep 11 2023, 13:21:10) [GCC 11.2.0]\n",
      "### NumPy version: 1.26.3\n",
      "### SciPy version: 1.11.4\n",
      "### Scikit-learn version: 1.3.0\n",
      "### Tensorflow version: 2.11.0\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import sklearn\n",
    "import utils\n",
    "\n",
    "# Let's check our software versions\n",
    "print('------------')\n",
    "print('### Python version: ' + __import__('sys').version)\n",
    "print(f'### NumPy version: {np.__version__}')\n",
    "print(f'### SciPy version: {sp.__version__}')\n",
    "print(f'### Scikit-learn version: {sklearn.__version__}')\n",
    "print(f'### Tensorflow version: {tf.__version__}')\n",
    "print('------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29486eba-fb6d-4891-bd0c-511666e4abd1",
   "metadata": {},
   "source": [
    "# Loading the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21ba8a6-de5d-4b3f-a668-0db22fbe77a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9193282-8b7e-4ec9-83a8-8d37182320a7",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27eb4d77-ee11-4295-8f69-5011ecb9bff4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/data.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Relative path to .npy files\u001b[39;00m\n\u001b[1;32m      5\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata.npz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load numpy arrays\u001b[39;00m\n\u001b[1;32m      9\u001b[0m train_x \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_x\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/cai4104/lib/python3.10/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/data.npz'"
     ]
    }
   ],
   "source": [
    "# Relative path to .npy files\n",
    "data_path = '../data/'\n",
    "\n",
    "# Relative path to .npy files\n",
    "data_path = '../data/'\n",
    "data = np.load(data_path + 'data.npz')\n",
    "\n",
    "# Load numpy arrays\n",
    "train_x = data['train_x']\n",
    "train_t = data['train_t']\n",
    "\n",
    "val_x = data['val_x']\n",
    "val_t = data['val_t']\n",
    "\n",
    "test_x = data['test_x']\n",
    "test_t = data['test_t']\n",
    "\n",
    "assert train_x.shape[0] == train_t.shape[0], \"Training image quantity mismatches label quantity\"\n",
    "assert val_x.shape[0] == val_t.shape[0], \"Validation image quantity mismatches label quantity\"\n",
    "assert test_x.shape[0] == test_t.shape[0], \"Test image quantity mismatches label quantity\"\n",
    "\n",
    "num_images = train_x.shape[0] + val_x.shape[0] + test_x.shape[0]\n",
    "image_shape = train_x.shape[1:]\n",
    "\n",
    "print(f'{num_images} images with shape {image_shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a24dff9-dfcc-4430-a80f-23e8144a2011",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_flat = train_x.reshape(train_x.shape[0], train_x.shape[1]*train_x.shape[2])\n",
    "val_x_flat = val_x.reshape(val_x.shape[0], val_x.shape[1]*val_x.shape[2])\n",
    "test_x_flat = test_x.reshape(test_x.shape[0], test_x.shape[1]*test_x.shape[2])\n",
    "\n",
    "train_t_num = np.array([np.argmax(a) for a in train_t])\n",
    "val_t_num = np.array([np.argmax(a) for a in val_t])\n",
    "test_t_num = np.array([np.argmax(a) for a in test_t])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88cc389-96e5-4f3d-a29e-1e40dc08c22a",
   "metadata": {},
   "source": [
    "# Function to evaluate each model\n",
    "## Metrics:\n",
    "####     - Accuracy\n",
    "####     - F1 Score\n",
    "####     - Precision\n",
    "####     - Recall\n",
    "####     - Area Under Curve (AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99bf40b-d686-488d-952b-1d9945069d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate (model):\n",
    "    return metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
