{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAI4104 Final Project: Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "### Python version: 3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]\n",
      "### NumPy version: 1.24.3\n",
      "### SciPy version: 1.11.1\n",
      "### Scikit-learn version: 1.3.0\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "# Let's check our software versions\n",
    "print('------------')\n",
    "print('### Python version: ' + __import__('sys').version)\n",
    "print(f'### NumPy version: {np.__version__}')\n",
    "print(f'### SciPy version: {sp.__version__}')\n",
    "print(f'### Scikit-learn version: {sklearn.__version__}')\n",
    "print('------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35887 images with shape (48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "# Relative path to .npy files\n",
    "data_path = '../data/'\n",
    "\n",
    "# Relative path to .npy files\n",
    "data_path = '../data/'\n",
    "data = np.load(data_path + 'data.npz')\n",
    "\n",
    "# Load numpy arrays\n",
    "train_x = data['train_x']\n",
    "train_t = data['train_t']\n",
    "\n",
    "val_x = data['val_x']\n",
    "val_t = data['val_t']\n",
    "\n",
    "test_x = data['test_x']\n",
    "test_t = data['test_t']\n",
    "\n",
    "assert train_x.shape[0] == train_t.shape[0], \"Training image quantity mismatches label quantity\"\n",
    "assert val_x.shape[0] == val_t.shape[0], \"Validation image quantity mismatches label quantity\"\n",
    "assert test_x.shape[0] == test_t.shape[0], \"Test image quantity mismatches label quantity\"\n",
    "\n",
    "num_images = train_x.shape[0] + val_x.shape[0] + test_x.shape[0]\n",
    "image_shape = train_x.shape[1:]\n",
    "\n",
    "print(f'{num_images} images with shape {image_shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_flat = train_x.reshape(train_x.shape[0], train_x.shape[1]*train_x.shape[2])\n",
    "val_x_flat = val_x.reshape(val_x.shape[0], val_x.shape[1]*val_x.shape[2])\n",
    "test_x_flat = test_x.reshape(test_x.shape[0], test_x.shape[1]*test_x.shape[2])\n",
    "\n",
    "train_t_num = np.array([np.argmax(a) for a in train_t])\n",
    "val_t_num = np.array([np.argmax(a) for a in val_t])\n",
    "test_t_num = np.array([np.argmax(a) for a in test_t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "def evaluate(model):\n",
    "\n",
    "    model.fit(train_x_flat, train_t_num)\n",
    "    train_y = model.predict(train_x_flat)\n",
    "    val_y = model.predict(val_x_flat)\n",
    "\n",
    "    train_acc = accuracy_score(train_t_num, train_y)\n",
    "    train_bal_acc = balanced_accuracy_score(train_t_num, train_y)\n",
    "\n",
    "    val_acc = accuracy_score(val_t_num, val_y)\n",
    "    val_bal_acc = balanced_accuracy_score(val_t_num, val_y)\n",
    "\n",
    "    print('Model Accuracies:')\n",
    "    print(f'Training:   Standard: {train_acc}   Balanced: {train_bal_acc}')\n",
    "    print(f'Validation:   Standard: {val_acc}   Balanced: {val_bal_acc}')\n",
    "\n",
    "    return train_y, val_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracies:\n",
      "Training:   Standard: 0.2519904458598726   Balanced: 0.14285714285714285\n",
      "Validation:   Standard: 0.245216422069478   Balanced: 0.14285714285714285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([3, 3, 3, ..., 3, 3, 3]), array([3, 3, 3, ..., 3, 3, 3]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "model_dm = DummyClassifier(strategy='most_frequent')\n",
    "evaluate(model_dm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracies:\n",
      "Training:   Standard: 0.214171974522293   Balanced: 0.23205352196206208\n",
      "Validation:   Standard: 0.21344974921047744   Balanced: 0.228924214403077\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create and train model, hyperparameter tuned using Grid Search\n",
    "model_nb = GaussianNB(var_smoothing=0.0012328467394420659)\n",
    "evaluate(model_nb)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "gs_NB = GridSearchCV(estimator=model_nb, \n",
    "                 param_grid=params_NB, \n",
    "                 verbose=1, \n",
    "                 scoring='accuracy') \n",
    "gs_NB.fit(train_x_flat, train_t_num)\n",
    "\n",
    "gs_NB.best_params_\n",
    "\"\"\";\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracies:\n",
      "Training:   Standard: 0.4967356687898089   Balanced: 0.4453942526704614\n",
      "Validation:   Standard: 0.3457180011146201   Balanced: 0.2857314189551788\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Create and train model\n",
    "model_lr = LogisticRegression(penalty='l2', C=0.5, multi_class='multinomial', solver='lbfgs', max_iter=5000, random_state=seed)\n",
    "\n",
    "# Evaluate model\n",
    "train_preds_lr, val_preds_lr = evaluate(model_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
